#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶: ocean_data_wrapper.py
ä½ç½®: Source/PythonEngine/wrappers/ocean_data_wrapper.py
åŠŸèƒ½: C#è°ƒç”¨data_processor.pyçš„åŒ…è£…å™¨è„šæœ¬
ç”¨æ³•: python ocean_data_wrapper.py input.json output.json
"""

import sys
import json
import numpy as np
from pathlib import Path
import traceback
import os
import math
import oceansim


# æ·»åŠ Pythonå¼•æ“è·¯å¾„åˆ°sys.path
current_dir = Path(__file__).parent
python_engine_root = current_dir.parent
sys.path.insert(0, str(python_engine_root.parent))


try:
    from PythonEngine.core.data_processor import DataProcessor
    from PythonEngine.core.netcdf_handler import NetCDFHandler
except ImportError as e:
    print(f"å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"Pythonè·¯å¾„: {sys.path}")
    sys.exit(1)

def nan_to_none(obj):
    if isinstance(obj, float) and math.isnan(obj):
        return None
    if isinstance(obj, dict):
        return {k: nan_to_none(v) for k, v in obj.items()}
    if isinstance(obj, list):
        return [nan_to_none(x) for x in obj]
    return obj


def load_netcdf_data(input_data):
    """åŠ è½½NetCDFæ•°æ®"""
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        if not netcdf_path:
            raise ValueError("netcdf_path æœªæä¾›ï¼Œæ— æ³•åŠ è½½ NetCDF")


        print(f"[INFO] æ­£åœ¨åŠ è½½NetCDFæ–‡ä»¶: {netcdf_path}")

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(netcdf_path):
            return {
                "success": False,
                "message": f"NetCDFæ–‡ä»¶ä¸å­˜åœ¨: {netcdf_path}",
                "data_info": {}
            }

        # æ‰“å¼€NetCDFæ–‡ä»¶
        handler = NetCDFHandler(netcdf_path)

        try:
            # è¯»å–æ•°æ®
            u, v, lat, lon = handler.get_uv(
                time_idx=params.get('time_idx', 0),
                depth_idx=params.get('depth_idx', 0)
            )

            print(f"[INFO] åŸå§‹æ•°æ®å½¢çŠ¶: u={u.shape}, v={v.shape}, lat={len(lat)}, lon={len(lon)}")

            # åº”ç”¨åœ°ç†èŒƒå›´è¿‡æ»¤
            original_u, original_v = u.copy(), v.copy()
            original_lat, original_lon = lat.copy(), lon.copy()

            if params.get('lon_min') is not None and params.get('lon_max') is not None:
                lon_mask = (lon >= params['lon_min']) & (lon <= params['lon_max'])
                lon = lon[lon_mask]
                u = u[:, lon_mask]
                v = v[:, lon_mask]
                print(f"[INFO] åº”ç”¨ç»åº¦è¿‡æ»¤å: lon={len(lon)}, u.shape={u.shape}")

            if params.get('lat_min') is not None and params.get('lat_max') is not None:
                lat_mask = (lat >= params['lat_min']) & (lat <= params['lat_max'])
                lat = lat[lat_mask]
                u = u[lat_mask, :]
                v = v[lat_mask, :]
                print(f"[INFO] åº”ç”¨çº¬åº¦è¿‡æ»¤å: lat={len(lat)}, u.shape={u.shape}")

            # æ•°æ®ç»Ÿè®¡
            u_valid = u[np.isfinite(u)]
            v_valid = v[np.isfinite(v)]
            speed = np.sqrt(u**2 + v**2)
            speed_valid = speed[np.isfinite(speed)]

            return {
                "success": True,
                "message": "NetCDFæ•°æ®åŠ è½½æˆåŠŸ",
                "data_info": {
                    "source_file": netcdf_path,
                    "time_index": params.get('time_idx', 0),
                    "depth_index": params.get('depth_idx', 0),
                    "original_shape": f"u={original_u.shape}, v={original_v.shape}",
                    "filtered_shape": f"u={u.shape}, v={v.shape}",
                    "lat_range": f"{lat.min():.3f} - {lat.max():.3f}",
                    "lon_range": f"{lon.min():.3f} - {lon.max():.3f}",
                    "u_range": f"{u_valid.min():.3f} - {u_valid.max():.3f}" if len(u_valid) > 0 else "æ— æœ‰æ•ˆæ•°æ®",
                    "v_range": f"{v_valid.min():.3f} - {v_valid.max():.3f}" if len(v_valid) > 0 else "æ— æœ‰æ•ˆæ•°æ®",
                    "max_speed": f"{speed_valid.max():.3f}" if len(speed_valid) > 0 else "0.000",
                    "valid_points": int(np.sum(np.isfinite(u) & np.isfinite(v))),
                    "total_points": int(u.size)
                },
                "dataset": {
                    "u": u.tolist(),
                    "v": v.tolist(),
                    "lat": lat.tolist(),
                    "lon": lon.tolist(),
                    "depth": params.get('depth_idx', 0),
                    "time_info": f"æ—¶é—´ç´¢å¼•: {params.get('time_idx', 0)}"
                }
            }

        finally:
            handler.close()

    except Exception as e:
        return {
            "success": False,
            "message": f"NetCDFæ•°æ®åŠ è½½å¤±è´¥: {str(e)}",
            "data_info": {},
            "error_trace": traceback.format_exc()
        }



def plot_vector_field(input_data):
    """ç®€åŒ–ç‰ˆ: ä»…ä¼ å…¥ netcdf_pathï¼Œè‡ªåŠ¨è¯»å–å¹¶ç»˜å›¾"""
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        if not netcdf_path or not os.path.exists(netcdf_path):
            raise ValueError(f"netcdf_path æœªæä¾›æˆ–æ–‡ä»¶ä¸å­˜åœ¨: {netcdf_path}")

        print(f"[INFO] è‡ªåŠ¨åŠ è½½NetCDFå¹¶ç”ŸæˆçŸ¢é‡åœº: {netcdf_path}")

        # å…ˆè¯»å–æ•°æ®
        handler = NetCDFHandler(netcdf_path)
        u, v, lat, lon = handler.get_uv(
            time_idx=params.get('time_idx', 0),
            depth_idx=params.get('depth_idx', 0)
        )

        handler.close()

        # è¯»å–æ—¶é—´ä¿¡æ¯
        selected_time_idx = params.get('time_idx', 0)
        time_value = handler.get_time(index=selected_time_idx)
        if not time_value:
            time_value = "æœªçŸ¥"

        # è¯»å–æ·±åº¦ä¿¡æ¯
        selected_depth_idx = params.get('depth_idx', 0)
        depth_value = handler.get_depth(index=selected_depth_idx)
        if depth_value is None:
            depth_value = 0.0


        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = DataProcessor(
            u=u,
            v=v,
            lat=lat,
            lon=lon,
            depth=depth_value,
            time_info=time_value
        )

        save_path = params.get('save_path', "auto_plot.png")

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

        print(f"[INFO] è¾“å‡ºå›¾åƒ: {save_path}")

        processor.plot_vector_field(
            save_path=save_path,
            skip=params.get('skip', 3),
            show=params.get('show', False),
            contourf_levels=params.get('contourf_levels', 100),
            contourf_cmap=params.get('contourf_cmap', 'coolwarm'),
            quiver_scale=params.get('quiver_scale', 30),
            quiver_width=params.get('quiver_width', 0.001),
            font_size=params.get('font_size', 14),
            dpi=params.get('dpi', 120)
        )

        if os.path.exists(save_path):
            file_size = os.path.getsize(save_path)
            return {
                "success": True,
                "message": "çŸ¢é‡åœºç»˜åˆ¶å®Œæˆ",
                "image_path": save_path,
                "metadata": {
                    "file_size_kb": round(file_size / 1024, 1),
                    "shape": str(u.shape)
                }
            }
        else:
            return {
                "success": False,
                "message": "å›¾åƒæ–‡ä»¶æœªèƒ½ç”Ÿæˆ",
                "image_path": save_path
            }

    except Exception as e:
        return {
            "success": False,
            "message": f"çŸ¢é‡åœºç»˜åˆ¶å¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc()
        }


def export_vector_shapefile(input_data):
    """å¯¼å‡ºçŸ¢é‡åœºä¸ºShapefile"""
    try:
        data = input_data['data']
        params = input_data['parameters']

        print(f"[INFO] æ­£åœ¨å¯¼å‡ºçŸ¢é‡åœºä¸ºShapefile...")

        # ä»è¾“å…¥æ•°æ®é‡å»ºnumpyæ•°ç»„
        u = np.array(data['u'])
        v = np.array(data['v'])
        lat = np.array(data['lat'])
        lon = np.array(data['lon'])

        # åˆ›å»ºæ•°æ®å¤„ç†å™¨
        processor = DataProcessor(u=u, v=v, lat=lat, lon=lon)

        # å¯¼å‡ºShapefile
        out_path = params['out_path']
        skip = params.get('skip', 5)
        file_type = params.get('file_type', 'shp')

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(out_path), exist_ok=True)

        processor.export_vector_shapefile(
            out_path=out_path,
            skip=skip,
            file_type=file_type
        )

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        expected_file = f"{out_path}.{file_type}"
        if os.path.exists(expected_file):
            file_size = os.path.getsize(expected_file)
            return {
                "success": True,
                "message": f"çŸ¢é‡åœºå·²æˆåŠŸå¯¼å‡ºä¸º{file_type.upper()}æ ¼å¼",
                "output_path": expected_file,
                "metadata": {
                    "file_size_kb": round(file_size / 1024, 1),
                    "file_type": file_type,
                    "skip_interval": skip,
                    "data_points_exported": f"çº¦{(u.size // (skip * skip))}ä¸ª"
                }
            }
        else:
            return {
                "success": False,
                "message": f"å¯¼å‡ºæ–‡ä»¶æœªèƒ½ç”Ÿæˆ: {expected_file}",
                "output_path": ""
            }

    except Exception as e:
        return {
            "success": False,
            "message": f"Shapefileå¯¼å‡ºå¤±è´¥: {str(e)}",
            "output_path": "",
            "error_trace": traceback.format_exc()
        }

def get_statistics(input_data):
    """è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯"""
    try:
        data = input_data['data']

        # ä»è¾“å…¥æ•°æ®é‡å»ºnumpyæ•°ç»„
        u = np.array(data['u'])
        v = np.array(data['v'])
        lat = np.array(data['lat'])
        lon = np.array(data['lon'])

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        u_valid = u[np.isfinite(u)]
        v_valid = v[np.isfinite(v)]
        speed = np.sqrt(u**2 + v**2)
        speed_valid = speed[np.isfinite(speed)]

        # è®¡ç®—æ–¹å‘
        direction = np.arctan2(v, u)
        direction_valid = direction[np.isfinite(direction)]
        direction_deg = np.degrees(direction_valid)

        statistics = {
            "data_dimensions": {
                "u_shape": list(u.shape),
                "v_shape": list(v.shape),
                "lat_points": len(lat),
                "lon_points": len(lon)
            },
            "geographic_extent": {
                "lat_min": float(lat.min()),
                "lat_max": float(lat.max()),
                "lon_min": float(lon.min()),
                "lon_max": float(lon.max()),
                "lat_span": float(lat.max() - lat.min()),
                "lon_span": float(lon.max() - lon.min())
            },
            "velocity_statistics": {
                "u_component": {
                    "min": float(u_valid.min()) if len(u_valid) > 0 else None,
                    "max": float(u_valid.max()) if len(u_valid) > 0 else None,
                    "mean": float(u_valid.mean()) if len(u_valid) > 0 else None,
                    "std": float(u_valid.std()) if len(u_valid) > 0 else None
                },
                "v_component": {
                    "min": float(v_valid.min()) if len(v_valid) > 0 else None,
                    "max": float(v_valid.max()) if len(v_valid) > 0 else None,
                    "mean": float(v_valid.mean()) if len(v_valid) > 0 else None,
                    "std": float(v_valid.std()) if len(v_valid) > 0 else None
                },
                "speed": {
                    "min": float(speed_valid.min()) if len(speed_valid) > 0 else None,
                    "max": float(speed_valid.max()) if len(speed_valid) > 0 else None,
                    "mean": float(speed_valid.mean()) if len(speed_valid) > 0 else None,
                    "std": float(speed_valid.std()) if len(speed_valid) > 0 else None
                }
            },
            "data_quality": {
                "total_points": int(u.size),
                "valid_points": int(np.sum(np.isfinite(u) & np.isfinite(v))),
                "invalid_points": int(np.sum(~(np.isfinite(u) & np.isfinite(v)))),
                "valid_percentage": float(np.sum(np.isfinite(u) & np.isfinite(v)) / u.size * 100)
            },
            "flow_characteristics": {
                "dominant_direction_deg": float(np.median(direction_deg)) if len(direction_deg) > 0 else None,
                "direction_variability": float(np.std(direction_deg)) if len(direction_deg) > 0 else None,
                "high_speed_points": int(np.sum(speed_valid > np.percentile(speed_valid, 90))) if len(speed_valid) > 0 else 0
            }
        }

        return {
            "success": True,
            "message": "æ•°æ®ç»Ÿè®¡è®¡ç®—å®Œæˆ",
            "statistics": statistics
        }

    except Exception as e:
        return {
            "success": False,
            "message": f"æ•°æ®ç»Ÿè®¡è®¡ç®—å¤±è´¥: {str(e)}",
            "statistics": {},
            "error_trace": traceback.format_exc()
        }

def create_ocean_animation(input_data):
    """
    åˆ›å»ºæ´‹æµæ—¶é—´åºåˆ—GIFåŠ¨ç”»ï¼Œå¤ç”¨ plot_vector_fieldï¼Œç¡®ä¿å’Œå•å¸§æ¸²æŸ“ä¸€è‡´
    """
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        output_path = params.get('output_path')
        frame_delay = params.get('frame_delay', 500)

        if not netcdf_path or not os.path.exists(netcdf_path):
            raise ValueError(f"NetCDFæ–‡ä»¶ä¸å­˜åœ¨: {netcdf_path}")

        print(f"[INFO] åˆ›å»ºæ´‹æµåŠ¨ç”»: {netcdf_path}")
        print(f"[INFO] å¸§å»¶è¿Ÿ: {frame_delay}ms")

        # æ‰“å¼€NetCDFæ–‡ä»¶
        handler = NetCDFHandler(netcdf_path)
        try:
            ds = handler.ds
            if 'time' not in ds.dims:
                raise ValueError("NetCDFæ–‡ä»¶ä¸­æ²¡æœ‰æ—¶é—´ç»´åº¦")

            total_time_steps = ds.dims['time']
            frame_stride = params.get("frame_stride", 1)
            time_indices = list(range(0, total_time_steps, max(1, frame_stride)))

            print(f"[INFO] NetCDFæ–‡ä»¶åŒ…å« {total_time_steps} ä¸ªæ—¶é—´æ­¥")
            print(f"[INFO] ä½¿ç”¨å¸§æ­¥é•¿ frame_stride={frame_stride}")
            print(f"[INFO] å°†ç”Ÿæˆ {len(time_indices)} å¸§åŠ¨ç”»")


            # ä¸´æ—¶å¸§ç›®å½•
            temp_dir = os.path.join(os.path.dirname(output_path), f"temp_frames_{os.getpid()}")
            os.makedirs(temp_dir, exist_ok=True)

            frame_files = []

            try:
                # å¤ç”¨ plot_vector_field
                for i, time_idx in enumerate(time_indices):
                    print(f"[INFO] æ¸²æŸ“å¸§ {i+1}/{len(time_indices)} (æ—¶é—´ç´¢å¼•: {time_idx})")

                    frame_path = os.path.join(temp_dir, f"frame_{i:03d}.png")

                    # ç»§æ‰¿å‚æ•°ï¼ŒåŠ¨æ€ä¿®æ”¹
                    plot_params = params.copy()
                    plot_params.update({
                        "time_idx": time_idx,
                        "save_path": frame_path,
                        "show": False
                    })

                    # ç›´æ¥è°ƒç”¨ plot_vector_field
                    plot_result = plot_vector_field({
                        "parameters": plot_params
                    })

                    if plot_result.get("success") and os.path.exists(frame_path):
                        frame_files.append(frame_path)
                    else:
                        print(f"[WARNING] ç¬¬ {i+1} å¸§ç”Ÿæˆå¤±è´¥")

                if not frame_files:
                    raise ValueError("æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å¸§")

                print(f"[INFO] åˆæˆGIFåŠ¨ç”»ï¼Œå¸§æ•°: {len(frame_files)}")
                _create_gif_from_frames(frame_files, output_path, frame_delay)

                if os.path.exists(output_path):
                    file_size = os.path.getsize(output_path)
                    print(f"[INFO] GIFåŠ¨ç”»ç”ŸæˆæˆåŠŸ: {output_path}")
                    return {
                        "success": True,
                        "message": "æ´‹æµåŠ¨ç”»ç”ŸæˆæˆåŠŸ",
                        "output_path": output_path,
                        "metadata": {
                            "frame_count": len(frame_files),
                            "file_size_mb": round(file_size / (1024 * 1024), 2),
                            "frame_delay_ms": frame_delay,
                            "total_time_steps": total_time_steps
                        }
                    }
                else:
                    return {
                        "success": False,
                        "message": "GIFæ–‡ä»¶æœªç”Ÿæˆ",
                        "output_path": output_path
                    }
            finally:
                # æ¸…ç†
                try:
                    for f in frame_files:
                        if os.path.exists(f):
                            os.remove(f)
                    if os.path.exists(temp_dir):
                        os.rmdir(temp_dir)
                except:
                    pass

        finally:
            handler.close()

    except Exception as e:
        return {
            "success": False,
            "message": f"æ´‹æµåŠ¨ç”»ç”Ÿæˆå¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc()
        }



def _create_gif_from_frames(frame_files, output_path, frame_delay):
    """ä»å¸§å›¾ç‰‡åˆ›å»ºGIFåŠ¨ç”»"""
    try:
        from PIL import Image

        # è¯»å–æ‰€æœ‰å¸§
        images = []
        for frame_file in frame_files:
            img = Image.open(frame_file)
            # è½¬æ¢ä¸ºRGBï¼ˆGIFéœ€è¦ï¼‰
            if img.mode != 'RGB':
                img = img.convert('RGB')
            images.append(img)

        if not images:
            raise ValueError("æ²¡æœ‰æœ‰æ•ˆçš„å¸§å›¾ç‰‡")

        # ä¿å­˜ä¸ºGIF
        images[0].save(
            output_path,
            save_all=True,
            append_images=images[1:],
            duration=frame_delay,
            loop=0,  # æ— é™å¾ªç¯
            optimize=True
        )

        print(f"[INFO] GIFä¿å­˜æˆåŠŸ: {output_path}")

    except ImportError:
        # å¦‚æœæ²¡æœ‰PILï¼Œå°è¯•ä½¿ç”¨matplotlib
        print("[INFO] PILä¸å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨matplotlibç”ŸæˆGIF")
        _create_gif_with_matplotlib(frame_files, output_path, frame_delay)
    except Exception as e:
        print(f"[ERROR] GIFåˆ›å»ºå¤±è´¥: {str(e)}")
        raise


def _create_gif_with_matplotlib(frame_files, output_path, frame_delay):
    """ä½¿ç”¨matplotlibåˆ›å»ºGIFï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    import matplotlib.pyplot as plt
    import matplotlib.animation as animation

    # è¯»å–ç¬¬ä¸€å¸§è·å–å°ºå¯¸
    first_img = plt.imread(frame_files[0])

    fig, ax = plt.subplots(figsize=(12, 10))
    ax.axis('off')

    # åˆå§‹åŒ–æ˜¾ç¤º
    im = ax.imshow(first_img)

    def animate(frame_idx):
        img = plt.imread(frame_files[frame_idx])
        im.set_array(img)
        return [im]

    # åˆ›å»ºåŠ¨ç”»
    anim = animation.FuncAnimation(
        fig, animate, frames=len(frame_files),
        interval=frame_delay, blit=True, repeat=True
    )

    # ä¿å­˜GIF
    try:
        anim.save(output_path, writer='pillow', fps=1000//frame_delay)
    except:
        # å¦‚æœpillow writerä¸å¯ç”¨ï¼Œå°è¯•é»˜è®¤writer
        anim.save(output_path, fps=1000//frame_delay)

    plt.close(fig)


def check_grid_data_formats(u, v, lat, lon):
    """æµ‹è¯•ä¸åŒçš„æ•°æ®æ ¼å¼ä»¥æ‰¾åˆ°ä¸oceansim.GridDataStructureå…¼å®¹çš„æ­£ç¡®æ–¹æ³•"""
    print(f"[TEST] å¼€å§‹æµ‹è¯•ç½‘æ ¼æ•°æ®æ ¼å¼å…¼å®¹æ€§")
    print(f"[TEST] åŸå§‹æ•°æ®å½¢çŠ¶: u={u.shape}, v={v.shape}")
    print(f"[TEST] åæ ‡æ•°ç»„é•¿åº¦: lat={len(lat)}, lon={len(lon)}")

    nx, ny = len(lon), len(lat)

    # æµ‹è¯•ä¸åŒçš„ç½‘æ ¼æ„é€ å‚æ•°å’Œæ•°æ®æ ¼å¼ç»„åˆ
    # é¦–å…ˆå°è¯•ä¸åæ ‡ç»´åº¦ä¸€è‡´çš„å¸¸è§„å¸ƒå±€
    try_configs = [
        {
            "name": "lon_lat",
            "grid": (len(lon), len(lat), 1),
            "u": u,
            "v": v,
        },
        {
            "name": "lat_lon",
            "grid": (len(lat), len(lon), 1),
            "u": u.T,
            "v": v.T,
        },
    ]

    for cfg in try_configs:
        config_name = cfg["name"]
        grid_params = cfg["grid"]
        try:
            print(f"[TEST] æµ‹è¯•é…ç½®: ç½‘æ ¼{grid_params}, æ•°æ®æ ¼å¼matrix")

            grid = oceansim.GridDataStructure(*grid_params, oceansim.CoordinateSystem.CARTESIAN)
            grid_dims = grid.get_dimensions()
            print(f"[TEST] ç½‘æ ¼ç»´åº¦: {grid_dims}")

            u_data = cfg["u"].astype(np.float64)
            v_data = cfg["v"].astype(np.float64)

            grid.add_field2d("test_u", u_data)
            grid.add_field2d("test_v", v_data)

            print(f"[TEST] âœ… æˆåŠŸæ‰¾åˆ°å…¼å®¹é…ç½®: {config_name}")
            return {
                "success": True,
                "grid_params": grid_params,
                "data_format": config_name,
                "grid": grid,
                "u_data": u_data,
                "v_data": v_data,
            }
        except Exception as e:
            print(f"[TEST] âŒ é…ç½®å¤±è´¥: {str(e)}")
            continue

    return {"success": False, "error": "æœªæ‰¾åˆ°å…¼å®¹é…ç½®"}


def _validate_grid_dimensions(u, v, lat, lon, grid):
    """éªŒè¯æ•°æ®ç»´åº¦ä¸ç½‘æ ¼ç»´åº¦çš„åŒ¹é…æ€§"""
    try:
        data_shape = u.shape
        ny_data, nx_data = data_shape

        grid_dims = grid.get_dimensions()
        ny_grid, nx_grid = grid_dims[0], grid_dims[1]

        if ny_data != ny_grid or nx_data != nx_grid:
            raise ValueError(
                f"æ•°æ®ç»´åº¦ä¸åŒ¹é…: æ•°æ®å½¢çŠ¶ä¸º ({ny_data}, {nx_data}), "
                f"ç½‘æ ¼æœŸæœ›ä¸º ({ny_grid}, {nx_grid})"
            )

        if len(lat) != ny_data:
            raise ValueError(f"çº¬åº¦æ•°ç»„é•¿åº¦ {len(lat)} ä¸æ•°æ®çº¬åº¦ç»´åº¦ {ny_data} ä¸åŒ¹é…")

        if len(lon) != nx_data:
            raise ValueError(f"ç»åº¦æ•°ç»„é•¿åº¦ {len(lon)} ä¸æ•°æ®ç»åº¦ç»´åº¦ {nx_data} ä¸åŒ¹é…")

        if u.shape != v.shape:
            raise ValueError(f"Uå’ŒVåˆ†é‡ç»´åº¦ä¸åŒ¹é…: Uå½¢çŠ¶ä¸º {u.shape}, Vå½¢çŠ¶ä¸º {v.shape}")

        print(f"[DEBUG] ç»´åº¦éªŒè¯é€šè¿‡: æ•°æ® {data_shape}, ç½‘æ ¼ ({ny_grid}, {nx_grid})")
        return True

    except Exception as e:
        print(f"[ERROR] ç»´åº¦éªŒè¯å¤±è´¥: {str(e)}")
        raise


def calculate_vorticity_divergence(input_data):
    """è®¡ç®—æ¶¡åº¦åœºå’Œæ•£åº¦åœº - ä½¿ç”¨oceansim.CurrentFieldSolver"""
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        output_path = params.get('output_path')
        time_index = params.get('time_index', 0)
        depth_index = params.get('depth_index', 0)

        print(f"[INFO] ä½¿ç”¨oceansim.CurrentFieldSolverè®¡ç®—æ•£åº¦åœº: æ—¶é—´{time_index}, æ·±åº¦{depth_index}")

        handler = NetCDFHandler(netcdf_path)
        try:
            u, v, lat, lon = handler.get_uv(time_idx=time_index, depth_idx=depth_index)

            # è‡ªåŠ¨æµ‹è¯•å¹¶æ‰¾åˆ°å…¼å®¹çš„é…ç½®
            test_result = check_grid_data_formats(u, v, lat, lon)
            if not test_result["success"]:
                raise ValueError(f"æ— æ³•æ‰¾åˆ°å…¼å®¹çš„ç½‘æ ¼æ•°æ®æ ¼å¼: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # ä½¿ç”¨æµ‹è¯•æˆåŠŸçš„é…ç½®é‡æ–°åˆ›å»ºç½‘æ ¼
            grid_params = test_result["grid_params"]
            data_format = test_result["data_format"]

            print(f"[INFO] ä½¿ç”¨é…ç½®: ç½‘æ ¼{grid_params}, æ•°æ®æ ¼å¼{data_format}")

            grid = oceansim.GridDataStructure(*grid_params, oceansim.CoordinateSystem.CARTESIAN)

            # è®¾ç½®ç½‘æ ¼é—´è·
            dx = abs(lon[1] - lon[0]) * 111000
            dy = abs(lat[1] - lat[0]) * 111000

            # åˆ›å»ºç‰©ç†å‚æ•°å’Œæ´‹æµåœºæ±‚è§£å™¨
            params_obj = oceansim.PhysicalParameters()
            current_solver = oceansim.CurrentFieldSolver(grid, params_obj)

            # æ ¹æ®æµ‹è¯•ç»“æœå‡†å¤‡æ•°æ®
            u_data = test_result.get("u_data")
            v_data = test_result.get("v_data")
            if u_data is None or v_data is None:
                u_data = u.astype(np.float64)
                v_data = v.astype(np.float64)

            # è®¾ç½®é€Ÿåº¦åœºæ•°æ®åˆ°ç½‘æ ¼
            grid.add_field2d("u_velocity", u_data)
            grid.add_field2d("v_velocity", v_data)

            # ä½¿ç”¨C++è®¡ç®—æ•£åº¦
            divergence_result = current_solver.compute_divergence()

            # æ ¹æ®ç½‘æ ¼é…ç½®æ­£ç¡®é‡å¡‘æ•£åº¦ç»“æœ
            if grid_params[0] == len(lat):  # ny, nx, 1
                divergence = np.array(divergence_result).reshape(len(lat), len(lon))
            else:  # nx, ny, 1
                divergence = np.array(divergence_result).reshape(len(lon), len(lat)).T

            # è®¡ç®—æ¶¡åº¦
            vorticity = _calculate_vorticity_python(u, v, dx, dy)

            # å¯è§†åŒ–
            _plot_vorticity_divergence(lon, lat, vorticity, divergence, output_path)

            # ç»Ÿè®¡è®¡ç®—
            vort_stats = _compute_vorticity_stats(vorticity)
            div_stats = _compute_divergence_stats(divergence)

            return {
                "success": True,
                "message": "æ¶¡åº¦æ•£åº¦åœºè®¡ç®—å®Œæˆï¼ˆoceansimåç«¯ï¼‰",
                "output_path": output_path,
                "statistics": {
                    "vorticity": vort_stats,
                    "divergence": div_stats
                }
            }

        finally:
            handler.close()

    except Exception as e:
        return {
            "success": False,
            "message": f"æ¶¡åº¦æ•£åº¦åœºè®¡ç®—å¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc()
        }


def calculate_flow_statistics(input_data):
    """è®¡ç®—æµé€Ÿç»Ÿè®¡åˆ†å¸ƒ - ä½¿ç”¨oceansimå¢å¼ºåŠŸèƒ½"""
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        time_index = params.get('time_index', 0)
        depth_index = params.get('depth_index', 0)

        print(f"[INFO] ä½¿ç”¨oceansimè®¡ç®—æµé€Ÿç»Ÿè®¡: æ—¶é—´{time_index}, æ·±åº¦{depth_index}")

        handler = NetCDFHandler(netcdf_path)
        try:
            u, v, lat, lon = handler.get_uv(time_idx=time_index, depth_idx=depth_index)

            print(f"[DEBUG] u.shape = {u.shape}, åæ ‡é•¿åº¦: lat={len(lat)}, lon={len(lon)}")

            # åŸºç¡€æµé€Ÿè®¡ç®—
            speed = np.sqrt(u**2 + v**2)
            direction = np.arctan2(v, u)
            valid_mask = np.isfinite(speed)
            valid_speed = speed[valid_mask]
            valid_direction = direction[valid_mask]

            # è‡ªåŠ¨æµ‹è¯•å¹¶æ‰¾åˆ°å…¼å®¹çš„é…ç½®
            test_result = check_grid_data_formats(u, v, lat, lon)
            if not test_result["success"]:
                raise ValueError(f"æ— æ³•æ‰¾åˆ°å…¼å®¹çš„ç½‘æ ¼æ•°æ®æ ¼å¼: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            # ä½¿ç”¨æµ‹è¯•æˆåŠŸçš„é…ç½®
            grid_params = test_result["grid_params"]
            data_format = test_result["data_format"]

            print(f"[INFO] ä½¿ç”¨é…ç½®: ç½‘æ ¼{grid_params}, æ•°æ®æ ¼å¼{data_format}")

            grid = oceansim.GridDataStructure(*grid_params)
            params_obj = oceansim.PhysicalParameters()
            current_solver = oceansim.CurrentFieldSolver(grid, params_obj)

            # æ ¹æ®æµ‹è¯•ç»“æœå‡†å¤‡æ•°æ®
            u_data = test_result.get("u_data")
            v_data = test_result.get("v_data")
            if u_data is None or v_data is None:
                u_data = u.astype(np.float64)
                v_data = v.astype(np.float64)

            # è®¾ç½®é€Ÿåº¦åœº
            grid.add_field2d("u_velocity", u_data)
            grid.add_field2d("v_velocity", v_data)

            # ä½¿ç”¨C++è®¡ç®—åŠ¨èƒ½å’Œå…¶ä»–æŒ‡æ ‡
            try:
                kinetic_energy_field = current_solver.compute_kinetic_energy()
                total_energy = current_solver.compute_total_energy()
                mass_imbalance = current_solver.compute_mass_imbalance()
                kinetic_energy = float(np.mean(kinetic_energy_field))
            except Exception as e:
                print(f"[WARNING] C++é«˜çº§è®¡ç®—å¤±è´¥: {e}")
                kinetic_energy = float(0.5 * 1025 * np.mean(valid_speed**2))
                total_energy = kinetic_energy
                mass_imbalance = 0.0

            # åŸºç¡€ç»Ÿè®¡
            flow_stats = {
                "mean_speed": float(np.mean(valid_speed)),
                "max_speed": float(np.max(valid_speed)),
                "speed_standard_deviation": float(np.std(valid_speed)),
                "dominant_direction": float(np.degrees(np.median(valid_direction))),
                "kinetic_energy_density": kinetic_energy
            }

            # é«˜çº§æµ·æ´‹å­¦æŒ‡æ ‡
            oceanographic_metrics = {
                "total_energy": total_energy,
                "mass_conservation": {
                    "mass_imbalance": mass_imbalance,
                    "conservation_quality": "è‰¯å¥½" if abs(mass_imbalance) < 1e-6 else "éœ€è¦å…³æ³¨"
                },
                "geophysical_parameters": _compute_geophysical_parameters(lat, valid_speed)
            }

            return {
                "success": True,
                "message": "æµé€Ÿç»Ÿè®¡è®¡ç®—å®Œæˆï¼ˆoceansimå¢å¼ºï¼‰",
                "statistics": {
                    "flow_statistics": flow_stats,
                    "oceanographic_metrics": oceanographic_metrics
                }
            }

        finally:
            handler.close()

    except Exception as e:
        return {
            "success": False,
            "message": f"æµé€Ÿç»Ÿè®¡è®¡ç®—å¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc()
        }

def _calculate_vorticity_python(u, v, dx, dy):
    """Pythonå®ç°çš„æ¶¡åº¦è®¡ç®—ï¼ˆå› C++æ¥å£ä¸­æœªæ‰¾åˆ°æ¶¡åº¦å‡½æ•°ï¼‰"""
    vorticity = np.zeros_like(u)

    for i in range(1, u.shape[0] - 1):
        for j in range(1, u.shape[1] - 1):
            dvdx = (v[i, j+1] - v[i, j-1]) / (2 * dx)
            dudy = (u[i+1, j] - u[i-1, j]) / (2 * dy)
            vorticity[i, j] = dvdx - dudy

    return vorticity


def _compute_geophysical_parameters(lat, valid_speed):
    """è®¡ç®—åœ°çƒç‰©ç†å‚æ•°"""
    try:
        # åˆ›å»ºç‰©ç†å‚æ•°å¯¹è±¡
        params = oceansim.PhysicalParameters()

        # è®¡ç®—ä¸­å¿ƒçº¬åº¦çš„ç§‘é‡Œå¥¥åˆ©å‚æ•°
        center_lat = lat[len(lat)//2]
        # æ³¨æ„ï¼šéœ€è¦ç¡®è®¤PhysicalParametersæ˜¯å¦æœ‰è®¡ç®—ç§‘é‡Œå¥¥åˆ©å‚æ•°çš„æ–¹æ³•
        # ä»æ¥å£æ–‡æ¡£çœ‹åˆ°æœ‰coriolis_få±æ€§ï¼Œä½†å¯èƒ½éœ€è¦è®¾ç½®çº¬åº¦

        # æš‚æ—¶ä½¿ç”¨ç»å…¸å…¬å¼è®¡ç®—ç§‘é‡Œå¥¥åˆ©å‚æ•°
        omega_earth = 7.2921e-5  # åœ°çƒè‡ªè½¬è§’é€Ÿåº¦
        coriolis_f = 2 * omega_earth * np.sin(np.radians(center_lat))

        # è®¡ç®—ç½—æ–¯è´æ•°ï¼ˆç‰¹å¾é€Ÿåº¦/ç§‘é‡Œå¥¥åˆ©å‚æ•°/ç‰¹å¾é•¿åº¦ï¼‰
        characteristic_speed = np.mean(valid_speed)
        characteristic_length = 100000  # å‡è®¾ç‰¹å¾é•¿åº¦100km
        rossby_number = characteristic_speed / (abs(coriolis_f) * characteristic_length) if abs(coriolis_f) > 1e-10 else 0.0

        return {
            "latitude": float(center_lat),
            "coriolis_parameter": float(coriolis_f),
            "rossby_number": float(rossby_number),
            "characteristic_speed": float(characteristic_speed)
        }

    except Exception as e:
        print(f"[WARNING] åœ°çƒç‰©ç†å‚æ•°è®¡ç®—å¤±è´¥: {e}")
        return {
            "latitude": float(lat[len(lat)//2]),
            "coriolis_parameter": 0.0,
            "rossby_number": 0.0,
            "characteristic_speed": 0.0
        }


def _generate_levels(field, num_levels=21):
    """æ ¹æ®æ•°æ®ç”Ÿæˆç¨³å®šçš„ç­‰å€¼çº¿çº§åˆ«ï¼Œé¿å…çº§åˆ«éé€’å¢å¯¼è‡´ç»˜å›¾é”™è¯¯"""
    finite_vals = field[np.isfinite(field)]
    if finite_vals.size == 0:
        return np.linspace(-1, 1, num_levels)

    low = np.nanpercentile(finite_vals, 5)
    high = np.nanpercentile(finite_vals, 95)

    if not np.isfinite(low) or not np.isfinite(high) or low == high:
        span = abs(low) if np.isfinite(low) else 1.0
        low -= span * 0.1
        high += span * 0.1
        if low == high:
            low -= 1e-6
            high += 1e-6

    if high < low:
        low, high = high, low
    if high == low:
        high += 1e-6

    return np.linspace(low, high, num_levels)


def _plot_vorticity_divergence(lon, lat, vorticity, divergence, output_path):
    """ç»˜åˆ¶æ¶¡åº¦å’Œæ•£åº¦åœº"""
    import matplotlib.pyplot as plt
    import cartopy.crs as ccrs
    import cartopy.feature as cfeature
    from Source.PythonEngine.utils.chinese_config import setup_chinese_all

    setup_chinese_all(font_size=12, dpi=120)

    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8),
                                   subplot_kw={'projection': ccrs.PlateCarree()})

    lon_grid, lat_grid = np.meshgrid(lon, lat)

    # æ¶¡åº¦åœº
    vort_levels = _generate_levels(vorticity)
    cs1 = ax1.contourf(lon_grid, lat_grid, vorticity,
                       levels=vort_levels, cmap='RdBu_r',
                       transform=ccrs.PlateCarree())
    ax1.add_feature(cfeature.COASTLINE)
    ax1.add_feature(cfeature.LAND, facecolor='lightgray')
    ax1.set_title('ç›¸å¯¹æ¶¡åº¦åœº (sâ»Â¹)')
    plt.colorbar(cs1, ax=ax1, orientation='horizontal', shrink=0.8)

    # æ•£åº¦åœºï¼ˆoceansimè®¡ç®—ï¼‰
    div_levels = _generate_levels(divergence)
    cs2 = ax2.contourf(lon_grid, lat_grid, divergence,
                       levels=div_levels, cmap='RdYlBu_r',
                       transform=ccrs.PlateCarree())
    ax2.add_feature(cfeature.COASTLINE)
    ax2.add_feature(cfeature.LAND, facecolor='lightgray')
    ax2.set_title('æ•£åº¦åœº (sâ»Â¹) - oceansimè®¡ç®—')
    plt.colorbar(cs2, ax=ax2, orientation='horizontal', shrink=0.8)

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()


def _compute_vorticity_stats(vorticity):
    """è®¡ç®—æ¶¡åº¦ç»Ÿè®¡"""
    valid_vort = vorticity[np.isfinite(vorticity)]

    if len(valid_vort) == 0:
        return {"mean_vorticity": 0, "max_vorticity": 0, "min_vorticity": 0,
                "vorticity_variance": 0, "cyclone_count": 0, "anticyclone_count": 0}

    cyclone_threshold = np.percentile(valid_vort, 90)
    anticyclone_threshold = np.percentile(valid_vort, 10)

    return {
        "mean_vorticity": float(np.mean(valid_vort)),
        "max_vorticity": float(np.max(valid_vort)),
        "min_vorticity": float(np.min(valid_vort)),
        "vorticity_variance": float(np.var(valid_vort)),
        "cyclone_count": int(np.sum(vorticity > cyclone_threshold)),
        "anticyclone_count": int(np.sum(vorticity < anticyclone_threshold))
    }


def _compute_divergence_stats(divergence):
    """è®¡ç®—æ•£åº¦ç»Ÿè®¡"""
    valid_div = divergence[np.isfinite(divergence)]

    if len(valid_div) == 0:
        return {"mean_divergence": 0, "max_divergence": 0, "min_divergence": 0,
                "convergence_zones": 0, "divergence_zones": 0}

    return {
        "mean_divergence": float(np.mean(valid_div)),
        "max_divergence": float(np.max(valid_div)),
        "min_divergence": float(np.min(valid_div)),
        "convergence_zones": int(np.sum(divergence < -1e-5)),
        "divergence_zones": int(np.sum(divergence > 1e-5))
    }


def simulate_particle_tracking(input_data):
    """æ‹‰æ ¼æœ—æ—¥ç²’å­è¿½è¸ªæ¨¡æ‹Ÿ"""
    try:
        params = input_data.get('parameters', {})
        netcdf_path = params.get('netcdf_path')
        time_index = params.get('time_index', 0)
        depth_index = params.get('depth_index', 0)
        dt = params.get('dt', 3600.0)
        steps = params.get('steps', 24)
        initial_positions = np.array(params.get('initial_positions', []), dtype=float)
        output_path = params.get('output_path', 'particle_tracks.png')

        if initial_positions.size == 0:
            raise ValueError('initial_positions ä¸èƒ½ä¸ºç©º')

        print(f"[INFO] è¿è¡Œç²’å­è¿½è¸ªæ¨¡æ‹Ÿ: æ—¶é—´ç´¢å¼•{time_index}, æ·±åº¦ç´¢å¼•{depth_index}")

        handler = NetCDFHandler(netcdf_path)
        try:
            u, v, lat, lon = handler.get_uv(time_idx=time_index, depth_idx=depth_index)

            test_result = check_grid_data_formats(u, v, lat, lon)
            if not test_result["success"]:
                raise ValueError(f"æ— æ³•æ‰¾åˆ°å…¼å®¹çš„ç½‘æ ¼æ•°æ®æ ¼å¼: {test_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

            grid_params = test_result["grid_params"]
            u_data = test_result.get("u_data")
            v_data = test_result.get("v_data")
            if u_data is None or v_data is None:
                u_data = u.astype(np.float64)
                v_data = v.astype(np.float64)

            grid = oceansim.GridDataStructure(*grid_params)
            grid.add_field2d("u_velocity", u_data)
            grid.add_field2d("v_velocity", v_data)
            try:
                grid.add_vector_field("velocity", [u_data, v_data, np.zeros_like(u_data)])
            except Exception:
                pass

            rk_solver = oceansim.RungeKuttaSolver()
            simulator = oceansim.ParticleSimulator(grid, rk_solver)

            lon0, lat0 = float(lon.min()), float(lat.min())
            dx = float(lon[1]-lon[0]) if len(lon) > 1 else 1.0
            dy = float(lat[1]-lat[0]) if len(lat) > 1 else 1.0

            init_particles = []
            for p in initial_positions:
                ix = (p[0] - lon0) / dx
                iy = (p[1] - lat0) / dy
                init_particles.append([ix, iy, 0.0])

            simulator.initialize_particles(init_particles)

            trajectories = []
            for _ in range(steps):
                simulator.step_forward(dt)
                parts = simulator.get_particles()
                frame = []
                for pt in parts:
                    x = lon0 + pt.position[0] * dx
                    y = lat0 + pt.position[1] * dy
                    frame.append([x, y])
                trajectories.append(frame)

            _plot_particle_tracks(trajectories, lon, lat, output_path)

            return {
                "success": True,
                "message": "ç²’å­è¿½è¸ªæ¨¡æ‹Ÿå®Œæˆ",
                "output_path": output_path,
                "trajectories": trajectories,
            }
        finally:
            handler.close()
    except Exception as e:
        return {
            "success": False,
            "message": f"ç²’å­è¿½è¸ªæ¨¡æ‹Ÿå¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc(),
        }


def _plot_particle_tracks(trajectories, lon, lat, output_path):
    """ç»˜åˆ¶ç²’å­è½¨è¿¹"""
    import matplotlib.pyplot as plt
    import cartopy.crs as ccrs
    import cartopy.feature as cfeature
    from Source.PythonEngine.utils.chinese_config import setup_chinese_all

    setup_chinese_all(font_size=12, dpi=120)

    ax = plt.axes(projection=ccrs.PlateCarree())
    ax.add_feature(cfeature.COASTLINE)
    ax.add_feature(cfeature.LAND, facecolor='lightgray')
    ax.set_extent([float(lon.min()), float(lon.max()), float(lat.min()), float(lat.max())])

    for traj in trajectories:
        arr = np.array(traj)
        ax.plot(arr[:,0], arr[:,1], '-', transform=ccrs.PlateCarree(), linewidth=1)
        ax.plot(arr[0,0], arr[0,1], 'go', markersize=3, transform=ccrs.PlateCarree())
        ax.plot(arr[-1,0], arr[-1,1], 'ro', markersize=3, transform=ccrs.PlateCarree())

    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()

def main():
    if len(sys.argv) != 3:
        print("ç”¨æ³•: python ocean_data_wrapper.py input.json output.json")
        sys.exit(1)

    input_file = sys.argv[1]
    output_file = sys.argv[2]

    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            input_data = json.load(f)

        print(f"[INFO] å¤„ç†è¯·æ±‚ç±»å‹: {input_data.get('action', 'æœªçŸ¥')}")

        action = input_data.get('action', '')

        if action == 'load_netcdf':
            result = load_netcdf_data(input_data)
        elif action == 'plot_vector_field':
            result = plot_vector_field(input_data)
        elif action == 'export_vector_shapefile':
            result = export_vector_shapefile(input_data)
        elif action == 'get_statistics':
            result = get_statistics(input_data)
        elif action == 'create_ocean_animation':
            result = create_ocean_animation(input_data)
        elif action == 'calculate_vorticity_divergence':  # æ–°å¢ç»Ÿè®¡åˆ†æåŠŸèƒ½
            result = calculate_vorticity_divergence(input_data)
        elif action == 'calculate_flow_statistics':  # æ–°å¢æµé€Ÿç»Ÿè®¡åŠŸèƒ½
            result = calculate_flow_statistics(input_data)
        else:
            result = {
                "success": False,
                "message": f"æœªçŸ¥çš„è¯·æ±‚ç±»å‹: {action}"
            }

        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(nan_to_none(result), f, ensure_ascii=False, indent=2)

        print(f"[INFO] å¤„ç†å®Œæˆ: {result.get('message', 'æœªçŸ¥ç»“æœ')}")
        sys.exit(0 if result.get('success', False) else 1)

    except Exception as e:
        error_result = {
            "success": False,
            "message": f"åŒ…è£…å™¨æ‰§è¡Œå¤±è´¥: {str(e)}",
            "error_trace": traceback.format_exc()
        }

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(error_result, f, ensure_ascii=False, indent=2)
        except:
            pass

        print(f"[ERROR] é”™è¯¯: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    import json
    import os

    print("=" * 60)


    print("ğŸŒŠ æµ·æ´‹æ•°æ®ç»Ÿè®¡åˆ†ææ¨¡å—æµ‹è¯•")
    print("=" * 60)

    # æµ‹è¯•æ•°æ®è·¯å¾„
    test_netcdf_path = "/Users/beilsmindex/æ´‹æµæ¨¡æ‹Ÿ/OceanCurrentSimulationSystem/Source/PythonEngine/data/raw_data/merged_data.nc"

    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_netcdf_path):
        print(f"âŒ é”™è¯¯: æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨ - {test_netcdf_path}")
        exit(1)

    print(f"ğŸ“ æµ‹è¯•æ•°æ®æ–‡ä»¶: {os.path.basename(test_netcdf_path)}")
    print(f"ğŸ“ æ–‡ä»¶å¤§å°: {os.path.getsize(test_netcdf_path) / (1024*1024):.1f} MB")
    print()

    # ========== æµ‹è¯•1: æ¶¡åº¦æ•£åº¦åœºè®¡ç®— ==========
    print("ğŸ”„ æµ‹è¯•1: æ¶¡åº¦æ•£åº¦åœºè®¡ç®—")
    print("-" * 40)

    test_input_vort = {
        "action": "calculate_vorticity_divergence",
        "parameters": {
            "netcdf_path": test_netcdf_path,
            "output_path": "test_outputs/vorticity_divergence_analysis.png",
            "time_index": 0,
            "depth_index": 0
        }
    }

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs("test_outputs", exist_ok=True)

    print(f"âš™ï¸  æµ‹è¯•å‚æ•°:")
    print(f"   æ—¶é—´ç´¢å¼•: {test_input_vort['parameters']['time_index']}")
    print(f"   æ·±åº¦ç´¢å¼•: {test_input_vort['parameters']['depth_index']}")
    print(f"   è¾“å‡ºè·¯å¾„: {test_input_vort['parameters']['output_path']}")
    print()

    result_vort = calculate_vorticity_divergence(test_input_vort)

    print("ğŸ“Š æ¶¡åº¦æ•£åº¦åœºè®¡ç®—ç»“æœ:")
    if result_vort["success"]:
        print("âœ… è®¡ç®—æˆåŠŸ")
        print(f"ğŸ“ˆ è¾“å‡ºå›¾åƒ: {result_vort.get('output_path', 'æœªç”Ÿæˆ')}")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = result_vort.get("statistics", {})
        if "vorticity" in stats:
            vort_stats = stats["vorticity"]
            print(f"ğŸŒ€ æ¶¡åº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡æ¶¡åº¦: {vort_stats.get('mean_vorticity', 0):.6e} sâ»Â¹")
            print(f"   æœ€å¤§æ¶¡åº¦: {vort_stats.get('max_vorticity', 0):.6e} sâ»Â¹")
            print(f"   æœ€å°æ¶¡åº¦: {vort_stats.get('min_vorticity', 0):.6e} sâ»Â¹")
            print(f"   æ°”æ—‹åŒºåŸŸ: {vort_stats.get('cyclone_count', 0)} ä¸ª")
            print(f"   åæ°”æ—‹åŒºåŸŸ: {vort_stats.get('anticyclone_count', 0)} ä¸ª")

        if "divergence" in stats:
            div_stats = stats["divergence"]
            print(f"ğŸ“ æ•£åº¦ç»Ÿè®¡:")
            print(f"   å¹³å‡æ•£åº¦: {div_stats.get('mean_divergence', 0):.6e} sâ»Â¹")
            print(f"   æœ€å¤§æ•£åº¦: {div_stats.get('max_divergence', 0):.6e} sâ»Â¹")
            print(f"   æœ€å°æ•£åº¦: {div_stats.get('min_divergence', 0):.6e} sâ»Â¹")
            print(f"   è¾åˆåŒºåŸŸ: {div_stats.get('convergence_zones', 0)} ä¸ª")
            print(f"   è¾æ•£åŒºåŸŸ: {div_stats.get('divergence_zones', 0)} ä¸ª")

        # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
        output_path = result_vort.get('output_path')
        if output_path and os.path.exists(output_path):
            file_size = os.path.getsize(output_path)
            print(f"ğŸ’¾ ç”Ÿæˆæ–‡ä»¶å¤§å°: {file_size / 1024:.1f} KB")
    else:
        print("âŒ è®¡ç®—å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {result_vort.get('message', 'æœªçŸ¥é”™è¯¯')}")

    print("\n" + "=" * 60)

    # ========== æµ‹è¯•2: æµé€Ÿç»Ÿè®¡åˆ†æ ==========
    print("ğŸ”„ æµ‹è¯•2: æµé€Ÿç»Ÿè®¡åˆ†æ")
    print("-" * 40)

    test_input_flow = {
        "action": "calculate_flow_statistics",
        "parameters": {
            "netcdf_path": test_netcdf_path,
            "time_index": 0,
            "depth_index": 0
        }
    }

    print(f"âš™ï¸  æµ‹è¯•å‚æ•°:")
    print(f"   æ—¶é—´ç´¢å¼•: {test_input_flow['parameters']['time_index']}")
    print(f"   æ·±åº¦ç´¢å¼•: {test_input_flow['parameters']['depth_index']}")
    print()

    result_flow = calculate_flow_statistics(test_input_flow)

    print("ğŸ“Š æµé€Ÿç»Ÿè®¡åˆ†æç»“æœ:")
    if result_flow["success"]:
        print("âœ… è®¡ç®—æˆåŠŸ")

        # æ˜¾ç¤ºåŸºç¡€æµé€Ÿç»Ÿè®¡
        stats = result_flow.get("statistics", {})
        if "flow_statistics" in stats:
            flow_stats = stats["flow_statistics"]
            print(f"ğŸŒŠ åŸºç¡€æµé€Ÿç»Ÿè®¡:")
            print(f"   å¹³å‡æµé€Ÿ: {flow_stats.get('mean_speed', 0):.4f} m/s")
            print(f"   æœ€å¤§æµé€Ÿ: {flow_stats.get('max_speed', 0):.4f} m/s")
            print(f"   æµé€Ÿæ ‡å‡†å·®: {flow_stats.get('speed_standard_deviation', 0):.4f} m/s")
            print(f"   ä¸»å¯¼æ–¹å‘: {flow_stats.get('dominant_direction', 0):.1f}Â°")
            print(f"   åŠ¨èƒ½å¯†åº¦: {flow_stats.get('kinetic_energy_density', 0):.2f} J/mÂ³")

        # æ˜¾ç¤ºé«˜çº§æµ·æ´‹å­¦æŒ‡æ ‡
        if "oceanographic_metrics" in stats:
            ocean_metrics = stats["oceanographic_metrics"]
            print(f"ğŸŒ é«˜çº§æµ·æ´‹å­¦æŒ‡æ ‡:")
            print(f"   æ€»èƒ½é‡: {ocean_metrics.get('total_energy', 0):.2f} J/mÂ³")

            # è´¨é‡å®ˆæ’åˆ†æ
            mass_conservation = ocean_metrics.get("mass_conservation", {})
            print(f"âš–ï¸  è´¨é‡å®ˆæ’åˆ†æ:")
            print(f"   è´¨é‡ä¸å¹³è¡¡: {mass_conservation.get('mass_imbalance', 0):.2e}")
            print(f"   å®ˆæ’è´¨é‡: {mass_conservation.get('conservation_quality', 'æœªçŸ¥')}")

            # åœ°çƒç‰©ç†å‚æ•°
            geo_params = ocean_metrics.get("geophysical_parameters", {})
            print(f"ğŸŒ åœ°çƒç‰©ç†å‚æ•°:")
            print(f"   çº¬åº¦: {geo_params.get('latitude', 0):.2f}Â°")
            print(f"   ç§‘é‡Œå¥¥åˆ©å‚æ•°: {geo_params.get('coriolis_parameter', 0):.2e} sâ»Â¹")
            print(f"   ç½—æ–¯è´æ•°: {geo_params.get('rossby_number', 0):.4f}")
            print(f"   ç‰¹å¾æµé€Ÿ: {geo_params.get('characteristic_speed', 0):.4f} m/s")
    else:
        print("âŒ è®¡ç®—å¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {result_flow.get('message', 'æœªçŸ¥é”™è¯¯')}")

    print("\n" + "=" * 60)

    # ========== æµ‹è¯•3: æ‹‰æ ¼æœ—æ—¥ç²’å­è¿½è¸ª ==========
    print("ğŸ”„ æµ‹è¯•3: æ‹‰æ ¼æœ—æ—¥ç²’å­è¿½è¸ª")
    print("-" * 40)

    # é€‰æ‹©ä¸¤ä¸ªåˆå§‹ç²’å­ä½ç½®ç”¨äºç¤ºä¾‹
    handler = NetCDFHandler(test_netcdf_path)
    u_tmp, v_tmp, lat_tmp, lon_tmp = handler.get_uv(time_idx=0, depth_idx=0)
    handler.close()
    init_positions = [
        [float(lon_tmp[len(lon_tmp)//2]), float(lat_tmp[len(lat_tmp)//2])],
        [float(lon_tmp[len(lon_tmp)//3]), float(lat_tmp[len(lat_tmp)//3])]
    ]

    test_input_particles = {
        "action": "simulate_particle_tracking",
        "parameters": {
            "netcdf_path": test_netcdf_path,
            "time_index": 0,
            "depth_index": 0,
            "initial_positions": init_positions,
            "dt": 3600.0,
            "steps": 12,
            "output_path": "test_outputs/particle_tracks.png"
        }
    }

    print(f"âš™ï¸  ç²’å­æ•°: {len(init_positions)}, æ­¥æ•°: {test_input_particles['parameters']['steps']}")

    result_particles = simulate_particle_tracking(test_input_particles)

    print("ğŸ“Š ç²’å­è¿½è¸ªç»“æœ:")
    if result_particles["success"]:
        print("âœ… æ¨¡æ‹ŸæˆåŠŸ")
        print(f"ğŸ“ˆ è½¨è¿¹å›¾: {result_particles.get('output_path', 'æœªç”Ÿæˆ')}")
    else:
        print("âŒ æ¨¡æ‹Ÿå¤±è´¥")
        print(f"é”™è¯¯ä¿¡æ¯: {result_particles.get('message', 'æœªçŸ¥é”™è¯¯')}")

    print("\n" + "=" * 60)
    print("ğŸ¯ æµ‹è¯•å®Œæˆæ€»ç»“")
    print("-" * 40)

    # æµ‹è¯•ç»“æœæ€»ç»“
    vort_success = result_vort.get("success", False)
    flow_success = result_flow.get("success", False)
    particle_success = result_particles.get("success", False)

    print(f"æ¶¡åº¦æ•£åº¦åœºè®¡ç®—: {'âœ… æˆåŠŸ' if vort_success else 'âŒ å¤±è´¥'}")
    print(f"æµé€Ÿç»Ÿè®¡åˆ†æ: {'âœ… æˆåŠŸ' if flow_success else 'âŒ å¤±è´¥'}")
    print(f"ç²’å­è¿½è¸ªæ¨¡æ‹Ÿ: {'âœ… æˆåŠŸ' if particle_success else 'âŒ å¤±è´¥'}")

    if vort_success and flow_success and particle_success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æµ·æ´‹ç»Ÿè®¡åˆ†ææ¨¡å—è¿è¡Œæ­£å¸¸ã€‚")

        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        print("\nğŸ“ ç”Ÿæˆçš„è¾“å‡ºæ–‡ä»¶:")
        output_dir = "test_outputs"
        if os.path.exists(output_dir):
            for file in os.listdir(output_dir):
                file_path = os.path.join(output_dir, file)
                if os.path.isfile(file_path):
                    size_kb = os.path.getsize(file_path) / 1024
                    print(f"   {file} ({size_kb:.1f} KB)")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯å¹¶ä¿®å¤ç›¸å…³é—®é¢˜ã€‚")

    print("=" * 60)