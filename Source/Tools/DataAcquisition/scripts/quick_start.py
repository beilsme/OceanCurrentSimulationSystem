#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ä»¶: quick_start.py
åŠŸèƒ½: TOPAZç³»ç»Ÿæµ‹è¯•æ•°æ®å¿«é€Ÿä¸‹è½½è„šæœ¬
ä½œè€…: beilsm
ç‰ˆæœ¬: v1.0.0

ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºè·å–æœ€åŸºæœ¬çš„æµ‹è¯•æ•°æ®ï¼š
- å…¬å¼€çš„NOAAæµ·è¡¨æ¸©åº¦æ•°æ®
- GEBCOæµ·åº•åœ°å½¢æ•°æ®
- æ¨¡æ‹Ÿçš„è§‚æµ‹æ•°æ®ç”¨äºç®—æ³•æµ‹è¯•
"""

import os
import sys
import requests
import numpy as np
import netCDF4 as nc
from datetime import datetime, timedelta
from pathlib import Path
import logging
import time
import json
from typing import Tuple, Dict, Any


class QuickStartDownloader:
    """å¿«é€Ÿå¯åŠ¨æ•°æ®ä¸‹è½½å™¨ - æ— éœ€è®¤è¯çš„å…¬å¼€æ•°æ®"""

    def __init__(self, output_dir: str = "./test_data"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)

        # æµ‹è¯•åŒºåŸŸé…ç½® (æŒªå¨æµ·å°åŒºåŸŸ)
        self.test_region = {
            'lat_min': 65.0,
            'lat_max': 75.0,
            'lon_min': 0.0,
            'lon_max': 20.0
        }

        # æµ‹è¯•æ—¶é—´ (ä¸€å‘¨)
        self.test_dates = self.generate_test_dates("2008-04-01", 7)

        self.logger.info(f"å¿«é€Ÿå¯åŠ¨ä¸‹è½½å™¨åˆå§‹åŒ–å®Œæˆï¼Œè¾“å‡ºç›®å½•: {self.output_dir}")

    def generate_test_dates(self, start_date: str, num_days: int) -> list:
        """ç”Ÿæˆæµ‹è¯•æ—¥æœŸåˆ—è¡¨"""
        start = datetime.strptime(start_date, "%Y-%m-%d")
        return [(start + timedelta(days=i)).strftime("%Y-%m-%d") for i in range(num_days)]

    def download_file_simple(self, url: str, output_path: Path, chunk_size: int = 8192) -> bool:
        """ç®€å•çš„æ–‡ä»¶ä¸‹è½½æ–¹æ³•"""
        try:
            self.logger.info(f"ä¸‹è½½: {url}")

            response = requests.get(url, stream=True, timeout=300)
            response.raise_for_status()

            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)

            file_size = output_path.stat().st_size / (1024 * 1024)  # MB
            self.logger.info(f"ä¸‹è½½å®Œæˆ: {output_path.name} ({file_size:.2f} MB)")
            return True

        except Exception as e:
            self.logger.error(f"ä¸‹è½½å¤±è´¥: {str(e)}")
            return False

    def download_noaa_sst_sample(self) -> bool:
        """ä¸‹è½½NOAAæµ·è¡¨æ¸©åº¦æ ·æœ¬æ•°æ®"""
        self.logger.info("ä¸‹è½½NOAAæµ·è¡¨æ¸©åº¦æ•°æ®...")

        # NOAA OISSTé«˜åˆ†è¾¨ç‡æ•°æ® (å…¬å¼€è®¿é—®)
        base_url = "https://www.ncei.noaa.gov/data/sea-surface-temperature-optimum-interpolation/v2.1/access/avhrr"

        # ä¸‹è½½2008å¹´4æœˆçš„æ•°æ®
        year_month = "200804"
        filename = f"oisst-avhrr-v02r01.{year_month}01.nc"
        url = f"{base_url}/{year_month[:4]}/{year_month[4:]}/{filename}"

        output_path = self.output_dir / "sst" / filename

        return self.download_file_simple(url, output_path)

    def download_gebco_sample(self) -> bool:
        """ä¸‹è½½GEBCOæµ·åº•åœ°å½¢æ ·æœ¬æ•°æ®"""
        self.logger.info("ä¸‹è½½GEBCOæµ·åº•åœ°å½¢æ•°æ®...")

        # ä½¿ç”¨GEBCO Web APIè·å–åŒºåŸŸå­é›†
        bbox = f"{self.test_region['lon_min']},{self.test_region['lat_min']}," + \
               f"{self.test_region['lon_max']},{self.test_region['lat_max']}"

        # GEBCO 2023 Web Map Service
        url = f"https://www.gebco.net/data_and_products/gebco_web_services/web_map_service/mapserv?" + \
              f"request=GetMap&service=WMS&version=1.3.0&layers=GEBCO_LATEST&styles=default&" + \
              f"crs=EPSG:4326&bbox={bbox}&width=200&height=200&format=image/png"

        # æ”¹ç”¨ç›´æ¥çš„NetCDFä¸‹è½½é“¾æ¥ (å¦‚æœå¯ç”¨)
        gebco_url = "https://download.gebco.net/api/v1/coverage/gebco_2023.nc?" + \
                    f"bbox={bbox}&format=netcdf"

        output_path = self.output_dir / "bathymetry" / "gebco_test_region.nc"

        return self.download_file_simple(gebco_url, output_path)

    def create_synthetic_sla_data(self) -> bool:
        """åˆ›å»ºåˆæˆçš„æµ·å¹³é¢é«˜åº¦å¼‚å¸¸æ•°æ®ç”¨äºæµ‹è¯•"""
        self.logger.info("åˆ›å»ºåˆæˆæµ·å¹³é¢é«˜åº¦å¼‚å¸¸æ•°æ®...")

        try:
            # åˆ›å»ºç½‘æ ¼
            lats = np.linspace(self.test_region['lat_min'], self.test_region['lat_max'], 20)
            lons = np.linspace(self.test_region['lon_min'], self.test_region['lon_max'], 40)

            output_dir = self.output_dir / "sla_synthetic"
            output_dir.mkdir(parents=True, exist_ok=True)

            for date_str in self.test_dates:
                filename = f"sla_synthetic_{date_str.replace('-', '')}.nc"
                output_path = output_dir / filename

                # åˆ›å»ºåˆæˆæ•°æ® (æ¨¡æ‹ŸçœŸå®çš„æµ·æ´‹ä¿¡å·)
                LON, LAT = np.meshgrid(lons, lats)

                # æ·»åŠ æ—¶é—´å˜åŒ–
                day_of_year = datetime.strptime(date_str, "%Y-%m-%d").timetuple().tm_yday
                time_factor = np.sin(2 * np.pi * day_of_year / 365.0)

                # æ¨¡æ‹Ÿæµ·å¹³é¢é«˜åº¦å¼‚å¸¸ (cm)
                sla = (10 * np.sin(2 * np.pi * LON / 20) * np.cos(2 * np.pi * LAT / 10) +
                       5 * time_factor +
                       np.random.normal(0, 2, LON.shape))

                # åˆ›å»ºNetCDFæ–‡ä»¶
                with nc.Dataset(output_path, 'w') as ncfile:
                    # åˆ›å»ºç»´åº¦
                    ncfile.createDimension('latitude', len(lats))
                    ncfile.createDimension('longitude', len(lons))
                    ncfile.createDimension('time', 1)

                    # åˆ›å»ºå˜é‡
                    lat_var = ncfile.createVariable('latitude', 'f4', ('latitude',))
                    lon_var = ncfile.createVariable('longitude', 'f4', ('longitude',))
                    time_var = ncfile.createVariable('time', 'f4', ('time',))
                    sla_var = ncfile.createVariable('sla', 'f4', ('time', 'latitude', 'longitude'))

                    # å¡«å……æ•°æ®
                    lat_var[:] = lats
                    lon_var[:] = lons
                    time_var[0] = (datetime.strptime(date_str, "%Y-%m-%d") -
                                   datetime(1950, 1, 1)).days
                    sla_var[0, :, :] = sla

                    # æ·»åŠ å±æ€§
                    lat_var.units = 'degrees_north'
                    lon_var.units = 'degrees_east'
                    time_var.units = 'days since 1950-01-01'
                    sla_var.units = 'cm'
                    sla_var.long_name = 'Sea Level Anomaly'

                    # å…¨å±€å±æ€§
                    ncfile.title = 'Synthetic Sea Level Anomaly for TOPAZ Testing'
                    ncfile.source = 'Generated for EnKF algorithm testing'
                    ncfile.date_created = datetime.now().isoformat()

                self.logger.info(f"åˆ›å»ºåˆæˆSLAæ–‡ä»¶: {filename}")

            return True

        except Exception as e:
            self.logger.error(f"åˆ›å»ºåˆæˆSLAæ•°æ®å¤±è´¥: {str(e)}")
            return False

    def create_synthetic_argo_data(self) -> bool:
        """åˆ›å»ºåˆæˆçš„Argoå‰–é¢æ•°æ®"""
        self.logger.info("åˆ›å»ºåˆæˆArgoå‰–é¢æ•°æ®...")

        try:
            output_dir = self.output_dir / "argo_synthetic"
            output_dir.mkdir(parents=True, exist_ok=True)

            # åˆ›å»ºå‡ ä¸ªè™šæ‹Ÿçš„Argoå‰–é¢
            depths = np.array([0, 10, 20, 50, 100, 200, 500, 1000, 1500, 2000])

            for i, date_str in enumerate(self.test_dates[:3]):  # åªåˆ›å»º3ä¸ªå‰–é¢
                # éšæœºä½ç½®åœ¨æµ‹è¯•åŒºåŸŸå†…
                lat = np.random.uniform(self.test_region['lat_min'], self.test_region['lat_max'])
                lon = np.random.uniform(self.test_region['lon_min'], self.test_region['lon_max'])

                filename = f"argo_profile_{i+1}_{date_str.replace('-', '')}.nc"
                output_path = output_dir / filename

                # åˆ›å»ºå…¸å‹çš„åŒ—å¤§è¥¿æ´‹æ¸©ç›å‰–é¢
                temperature = 15 - 0.01 * depths - 0.001 * depths**1.2 + np.random.normal(0, 0.1, len(depths))
                salinity = 35.0 - 0.002 * depths + np.random.normal(0, 0.02, len(depths))

                # åº”ç”¨ç‰©ç†çº¦æŸ
                temperature = np.maximum(-2, np.minimum(25, temperature))
                salinity = np.maximum(30, np.minimum(37, salinity))

                with nc.Dataset(output_path, 'w') as ncfile:
                    # åˆ›å»ºç»´åº¦
                    ncfile.createDimension('N_LEVELS', len(depths))
                    ncfile.createDimension('N_PROF', 1)

                    # åˆ›å»ºå˜é‡
                    pres_var = ncfile.createVariable('PRES', 'f4', ('N_PROF', 'N_LEVELS'))
                    temp_var = ncfile.createVariable('TEMP', 'f4', ('N_PROF', 'N_LEVELS'))
                    sal_var = ncfile.createVariable('PSAL', 'f4', ('N_PROF', 'N_LEVELS'))
                    lat_var = ncfile.createVariable('LATITUDE', 'f4', ('N_PROF',))
                    lon_var = ncfile.createVariable('LONGITUDE', 'f4', ('N_PROF',))

                    # å¡«å……æ•°æ®
                    pres_var[0, :] = depths
                    temp_var[0, :] = temperature
                    sal_var[0, :] = salinity
                    lat_var[0] = lat
                    lon_var[0] = lon

                    # æ·»åŠ å±æ€§
                    pres_var.units = 'decibar'
                    temp_var.units = 'degree_Celsius'
                    sal_var.units = 'psu'
                    lat_var.units = 'degree_north'
                    lon_var.units = 'degree_east'

                    # å…¨å±€å±æ€§
                    ncfile.title = 'Synthetic Argo Profile for TOPAZ Testing'
                    ncfile.institution = 'Test Data Generator'
                    ncfile.date_created = datetime.now().isoformat()

                self.logger.info(f"åˆ›å»ºåˆæˆArgoå‰–é¢: {filename}")

            return True

        except Exception as e:
            self.logger.error(f"åˆ›å»ºåˆæˆArgoæ•°æ®å¤±è´¥: {str(e)}")
            return False

    def create_test_configuration(self) -> bool:
        """åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶"""
        self.logger.info("åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶...")

        config = {
            "test_metadata": {
                "description": "TOPAZ EnKFç³»ç»Ÿæµ‹è¯•æ•°æ®é›†",
                "region": "æŒªå¨æµ·æµ‹è¯•åŒºåŸŸ",
                "time_period": f"{self.test_dates[0]} åˆ° {self.test_dates[-1]}",
                "created": datetime.now().isoformat()
            },
            "spatial_domain": self.test_region,
            "temporal_domain": {
                "start_date": self.test_dates[0],
                "end_date": self.test_dates[-1],
                "num_days": len(self.test_dates)
            },
            "data_inventory": {
                "sea_surface_temperature": "NOAA OISST (çœŸå®æ•°æ®)",
                "sea_level_anomaly": "åˆæˆæ•°æ® (åŸºäºç‰©ç†æ¨¡å‹)",
                "argo_profiles": "åˆæˆæ•°æ® (å…¸å‹åŒ—å¤§è¥¿æ´‹å‰–é¢)",
                "bathymetry": "GEBCO (çœŸå®æ•°æ®)"
            },
            "enkf_parameters": {
                "ensemble_size": 20,  # æµ‹è¯•ç”¨å‡å°‘çš„é›†åˆå¤§å°
                "localization_radius_km": 100,
                "inflation_factor": 1.02,
                "grid_resolution_km": 50
            },
            "usage_notes": [
                "æ­¤æ•°æ®é›†ä»…ç”¨äºEnKFç®—æ³•åŠŸèƒ½æµ‹è¯•",
                "åˆæˆæ•°æ®åŒ…å«ç‰©ç†åˆç†çš„æµ·æ´‹ä¿¡å·",
                "ç½‘æ ¼åˆ†è¾¨ç‡å·²ä¼˜åŒ–ç”¨äºå¿«é€Ÿè®¡ç®—",
                "å®é™…åº”ç”¨éœ€è¦ä½¿ç”¨çœŸå®è§‚æµ‹æ•°æ®"
            ]
        }

        config_file = self.output_dir / "test_config.json"

        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)

        self.logger.info(f"æµ‹è¯•é…ç½®æ–‡ä»¶å·²ä¿å­˜: {config_file}")
        return True

    def validate_downloaded_data(self) -> Dict[str, Any]:
        """éªŒè¯ä¸‹è½½çš„æ•°æ®"""
        self.logger.info("éªŒè¯ä¸‹è½½çš„æ•°æ®...")

        validation_results = {
            "sst_data": False,
            "sla_data": False,
            "argo_data": False,
            "bathymetry_data": False,
            "total_size_mb": 0.0,
            "file_count": 0
        }

        # æ£€æŸ¥å„ç±»æ•°æ®æ–‡ä»¶
        data_dirs = {
            "sst": "sst_data",
            "sla_synthetic": "sla_data",
            "argo_synthetic": "argo_data",
            "bathymetry": "bathymetry_data"
        }

        for dir_name, result_key in data_dirs.items():
            data_dir = self.output_dir / dir_name
            if data_dir.exists():
                files = list(data_dir.glob("*.nc"))
                if files:
                    validation_results[result_key] = True
                    for file_path in files:
                        size_mb = file_path.stat().st_size / (1024 * 1024)
                        validation_results["total_size_mb"] += size_mb
                        validation_results["file_count"] += 1

        # ç”ŸæˆéªŒè¯æŠ¥å‘Š
        report_file = self.output_dir / "validation_report.json"
        with open(report_file, 'w') as f:
            json.dump(validation_results, f, indent=2)

        return validation_results

    def run_quick_download(self) -> bool:
        """æ‰§è¡Œå¿«é€Ÿä¸‹è½½æµç¨‹"""
        self.logger.info("å¼€å§‹å¿«é€Ÿæµ‹è¯•æ•°æ®ä¸‹è½½...")

        start_time = time.time()

        # æ‰§è¡Œä¸‹è½½ä»»åŠ¡
        tasks = [
            ("NOAAæµ·è¡¨æ¸©åº¦æ•°æ®", self.download_noaa_sst_sample),
            ("GEBCOæµ·åº•åœ°å½¢æ•°æ®", self.download_gebco_sample),
            ("åˆæˆæµ·å¹³é¢é«˜åº¦å¼‚å¸¸æ•°æ®", self.create_synthetic_sla_data),
            ("åˆæˆArgoå‰–é¢æ•°æ®", self.create_synthetic_argo_data),
            ("æµ‹è¯•é…ç½®æ–‡ä»¶", self.create_test_configuration)
        ]

        results = {}
        for task_name, task_func in tasks:
            self.logger.info(f"æ‰§è¡Œä»»åŠ¡: {task_name}")
            try:
                results[task_name] = task_func()
                if results[task_name]:
                    self.logger.info(f"âœ… {task_name} - å®Œæˆ")
                else:
                    self.logger.warning(f"âš ï¸ {task_name} - å¤±è´¥")
            except Exception as e:
                self.logger.error(f"âŒ {task_name} - é”™è¯¯: {str(e)}")
                results[task_name] = False

        # éªŒè¯æ•°æ®
        validation = self.validate_downloaded_data()

        end_time = time.time()

        # è¾“å‡ºæ‘˜è¦
        successful_tasks = sum(1 for success in results.values() if success)
        total_tasks = len(results)

        print("\n" + "="*60)
        print("TOPAZæµ‹è¯•æ•°æ®ä¸‹è½½å®Œæˆ!")
        print("="*60)
        print(f"æˆåŠŸä»»åŠ¡: {successful_tasks}/{total_tasks}")
        print(f"æ€»è€—æ—¶: {end_time - start_time:.1f} ç§’")
        print(f"æ•°æ®æ–‡ä»¶æ•°é‡: {validation['file_count']}")
        print(f"æ€»æ•°æ®å¤§å°: {validation['total_size_mb']:.1f} MB")
        print(f"è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")

        if successful_tasks == total_tasks:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•æ•°æ®å‡†å¤‡å°±ç»ª!")
            print("ğŸ’¡ ç°åœ¨å¯ä»¥å¼€å§‹æµ‹è¯•æ‚¨çš„EnKFç³»ç»Ÿäº†")
            return True
        else:
            print(f"\nâš ï¸ éƒ¨åˆ†ä»»åŠ¡å¤±è´¥ï¼Œä½†æ‚¨ä»å¯ä»¥ä½¿ç”¨å¯ç”¨çš„æ•°æ®è¿›è¡Œæµ‹è¯•")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("TOPAZ EnKFç³»ç»Ÿ - å¿«é€Ÿæµ‹è¯•æ•°æ®ä¸‹è½½å™¨")
    print("="*50)
    print("æ­¤è„šæœ¬å°†ä¸‹è½½å°é‡æµ‹è¯•æ•°æ®ï¼Œæ— éœ€è®¤è¯é…ç½®")
    print("é€‚åˆå¿«é€ŸéªŒè¯ç³»ç»ŸåŠŸèƒ½")
    print()

    # è·å–è¾“å‡ºç›®å½•
    output_dir = "./test_data"
    if len(sys.argv) > 1:
        output_dir = sys.argv[1]

    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print("å¼€å§‹ä¸‹è½½...")
    print()

    # åˆ›å»ºä¸‹è½½å™¨å¹¶æ‰§è¡Œ
    downloader = QuickStartDownloader(output_dir)

    try:
        success = downloader.run_quick_download()

        if success:
            print("\nä¸‹ä¸€æ­¥:")
            print("1. æ£€æŸ¥ç”Ÿæˆçš„test_config.jsoné…ç½®æ–‡ä»¶")
            print("2. è¿è¡Œæ‚¨çš„EnKFç³»ç»Ÿè¿›è¡Œæµ‹è¯•")
            print("3. å¦‚æœæµ‹è¯•æˆåŠŸï¼Œå¯ä»¥ä¸‹è½½å®Œæ•´çš„æ•°æ®é›†")

        sys.exit(0 if success else 1)

    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­ä¸‹è½½")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ ä¸‹è½½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()